# -*- coding: utf-8 -*-
"""MAIN PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XDx_TV81r6OI1w9t-k3cm2V1SbqlCrdv
"""

#import necessary libraries
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV

# Load dataset
df = pd.read_csv('Employee_Perfomance.csv')

# Selecting relevant features for analysis
features = ['Experience(months)', 'work_hours_logged', 'Task_completion_Rate',
            'Seniority_Level', 'Work_Quality_score', 'Feedback', 'Salary_Hike', 'Experience_Category']
target = 'Engagement_Score'  # Predicting performance based on Engagement_Score

# Encoding categorical variables
from sklearn.preprocessing import LabelEncoder, StandardScaler
label_encoders = {}
for col in ['Seniority_Level', 'Feedback', 'Salary_Hike', 'Experience_Category', 'Work_Quality_score']:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le  # Store encoders for future use

# Splitting data into training and testing sets
from sklearn.model_selection import train_test_split # Import train_test_split
X = df[features]
y = df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardizing numerical features
scaler = StandardScaler()
numeric_features = ['Experience(months)', 'work_hours_logged', 'Task_completion_Rate']
X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])
X_test[numeric_features] = scaler.transform(X_test[numeric_features])

# Hyperparameter tuning with GridSearchCV
from sklearn.model_selection import GridSearchCV # Import GridSearchCV
from sklearn.ensemble import RandomForestRegressor # Import RandomForestRegressor
from sklearn.model_selection import GridSearchCV # Import GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='r2', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best model from grid search
best_model = grid_search.best_estimator_
# Train the optimized model
best_model.fit(X_train, y_train)

# Predictions
y_pred = best_model.predict(X_test)

# Evaluate model performance
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score # Import necessary functions

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Best Model Parameters: {grid_search.best_params_}")
print(f"Mean Absolute Error: {mae:.2f}")
print(f"Mean Squared Error: {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# Encode categorical features
label_encoders = {}
categorical_cols = ['Gender', 'Job_Title', 'Department', 'Education',
                    'Seniority_Level', 'Work_Quality_score', 'Feedback',
                    'Salary_Hike', 'Experience_Category']

for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Define features and target
# Exclude 'Name' column from features
X = df.drop(['Employee_ID', 'Feedback', 'Name'], axis=1)  # Excluded 'Name' here
y = df['Feedback']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Support Vector Classifier (SVC)
from sklearn.svm import SVC
model = SVC(kernel='linear', random_state=42)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluate model
from sklearn.metrics import accuracy_score # Import the accuracy_score function
accuracy = accuracy_score(y_test, y_pred)
accuracy
accuracy = accuracy_score(y_test, y_pred)
accuracy

# Suppress warnings
import warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

# Define features and target
# Exclude 'Name' column from features
X = df.drop(['Employee_ID', 'Salary_Hike', 'Name'], axis=1)  # Excluded 'Name' here
y = df['Salary_Hike']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Logistic Regression model
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=500, random_state=42)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluate model
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
accuracy

# Save predictions to CSV for Power BI
df_test = pd.DataFrame(X_test, columns=[col for col in df.columns if col not in ['Employee_ID', 'Salary_Hike']])
df_test['Actual_Salary_Hike'] = y_test
df_test['Predicted_Salary_Hike'] = y_pred
df_test.to_csv("Processed_Employee_Performance.csv", index=False)

# Print evaluation metrics
print(f"Accuracy Score: {accuracy:.4f}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

# Selecting only relevant columns for analysis
import pandas as pd
df = pd.read_csv('Employee_Perfomance.csv')
final_features = ['Employee_ID', 'Experience(months)', 'work_hours_logged', 'Task_completion_Rate',
                  'Seniority_Level', 'Work_Quality_score', 'Feedback', 'Engagement_Score']

# Create final dataset
df_final = df[final_features]

# Save the processed data for Power BI
df_final.to_csv("Processed_Employee_Performance.csv", index=False)

print("Processed data saved successfully for Power BI.")

# Define performance metrics
performance_metrics = ['Engagement_Score', 'Task_completion_Rate', 'Work_Quality_score']

# Convert to numeric and handle missing values
df[performance_metrics] = df[performance_metrics].apply(pd.to_numeric, errors='coerce')
df[performance_metrics] = df[performance_metrics].fillna(df[performance_metrics].mean())

# Normalize using min-max scaling
for col in performance_metrics:
    min_val, max_val = df[col].min(), df[col].max()
    df[col] = (df[col] - min_val) / (max_val - min_val) if max_val > min_val else 0

# Compute Performance Score
weights = {'Engagement_Score': 0.4, 'Task_completion_Rate': 0.3, 'Work_Quality_score': 0.3}
df['Performance_Score'] = sum(df[col] * weights[col] for col in performance_metrics)

# Rank employees
df['Rank'] = df['Performance_Score'].rank(method='first', ascending=False).astype(int)

# Print to verify
print(df[['Performance_Score', 'Rank']].head())

# Save the ranked dataset
df.to_csv("Ranked_Employee_Performance.csv", index=False)

print("Ranking complete! Check 'Ranked_Employee_Performance.csv'.")

# create a bar plot to compare accuracies
import matplotlib.pyplot as plt

# Assuming you have accuracy values for KNN and Random Forest
# Example accuracy values
accuracy_svc = 0.61  # Replace with your actual KNN accuracy
accuracy_rf = 0.59
accuracy_LogReg = 0.72  # Replace with your actual Random Forest accuracy

plt.figure(figsize=(6, 4))
models = ['Support Vector Classifier', 'Random Forest','Logistic Regression']
accuracies = [accuracy_svc, accuracy_rf,accuracy_LogReg]
plt.bar(models, accuracies, color=['blue', 'green','red'])
plt.ylim(0, 1)
plt.title('Accuracy Comparison')
plt.ylabel('Accuracy')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
# Top 10 employees based on performance
top10 = df.sort_values('Performance_Score', ascending=False).head(10)
plt.figure(figsize=(10, 6))
sns.barplot(x='Performance_Score', y='Employee_ID', data=top10, palette='crest')
plt.title('Top 10 Employees by Performance Score')
plt.xlabel('Performance Score')
plt.ylabel('Employee ID')
plt.tight_layout()
plt.show()